library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 20
numep <- 100
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(200)
mu.t = numeric(200)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)*(es.t-mu.t))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=100)
act1 = mx.symbol.Activation(fc1, name='sig1', act_type='sigmoid')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=50, array.batch.size=200,
learning.rate=2e-6, momentum=0.9, eval.metric=mx.metric.rmse)
library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 20
numep <- 100
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(200)
mu.t = numeric(200)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)*(es.t-mu.t))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=10)
act1 = mx.symbol.Activation(fc1, name='sig1', act_type='tanh')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=10, array.batch.size=200,
learning.rate=2e-6, momentum=0.9, eval.metric=mx.metric.rmse)
library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 10
numep <- 50
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(200)
mu.t = numeric(200)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)*(es.t-mu.t))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=10)
act1 = mx.symbol.Activation(fc1, name='sig1', act_type='tanh')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=10, array.batch.size=200,
learning.rate=2e-4, momentum=0.9, eval.metric=mx.metric.rmse)
library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 10
numep <- 50
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(200)
mu.t = numeric(200)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)*(es.t-mu.t))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=10)
act1 = mx.symbol.Activation(fc1, name='sig1', act_type='tanh')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=100, array.batch.size=200,
learning.rate=2e-4, momentum=0.9, eval.metric=mx.metric.rmse)
library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 10
numep <- 50
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(200)
mu.t = numeric(200)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)*(es.t-mu.t))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=100)
act1 = mx.symbol.Activation(fc1, name='sig1', act_type='tanh')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=100, array.batch.size=200,
learning.rate=2e-4, momentum=0.9, eval.metric=mx.metric.rmse)
library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 10
numep <- 50
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(200)
mu.t = numeric(200)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)*(es.t-mu.t))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=100)
act1 = mx.symbol.Activation(fc1, name='sig1', act_type='sigmoid')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=100, array.batch.size=200,
learning.rate=2e-4, momentum=0.9, eval.metric=mx.metric.rmse)
library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 100
numep <- 20
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(200)
mu.t = numeric(200)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)*(es.t-mu.t))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=100)
act1 = mx.symbol.Activation(fc1, name='sig1', act_type='sigmoid')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=100, array.batch.size=200,
learning.rate=2e-4, momentum=0.9, eval.metric=mx.metric.rmse)
print(error)
library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 100
numep <- 20
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(1)
mu.t = numeric(1)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)*(es.t-mu.t))
print(mean(e))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=100)
act1 = mx.symbol.Activation(fc1, name='sig1', act_type='sigmoid')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=100, array.batch.size=200,
learning.rate=2e-4, momentum=0.9, eval.metric=mx.metric.rmse)
library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 100
numep <- 20
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(1)
mu.t = numeric(1)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)*(es.t-mu.t))
print(mean(error))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=100)
act1 = mx.symbol.Activation(fc1, name='sig1', act_type='sigmoid')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=100, array.batch.size=200,
learning.rate=2e-4, momentum=0.9, eval.metric=mx.metric.rmse)
preds = predict(model, test.x)
print(sqrt(mean((preds-test.y)^2)))
library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 100
numep <- 20
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(1)
mu.t = numeric(1)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)^2)
print(mean(error))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=100)
act1 = mx.symbol.Activation(fc1, name='sig1', act_type='sigmoid')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=10, array.batch.size=20,
learning.rate=2e-4, momentum=0.9, eval.metric=mx.metric.rmse)
library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 10
numep <- 20
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(1)
mu.t = numeric(1)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)^2)
print(mean(error))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=100)
act1 = mx.symbol.Activation(fc1, name='sig1', act_type='tanh')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=10, array.batch.size=200,
learning.rate=2e-4, momentum=0.9, eval.metric=mx.metric.rmse)
preds = predict(model, test.x)
print(sqrt(mean((preds-test.y)^2)))
library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 10
numep <- 20
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(1)
mu.t = numeric(1)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)^2)
print(mean(error))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=100)
act1 = mx.symbol.Activation(fc1, name='sig1', act_type='tanh')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=10, array.batch.size=200,
learning.rate=2e-4, momentum=0.9, eval.metric=mx.metric.rmse)
library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 10
numep <- 20
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(1)
mu.t = numeric(1)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)^2)
print(mean(error))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=100)
act1 = mx.symbol.Activation(fc1, name='sig1', act_type='tanh')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=10, array.batch.size=200,
learning.rate=2e-4, momentum=0.9, eval.metric=mx.metric.rmse)
library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 10
numep <- 20
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(1)
mu.t = numeric(1)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)^2)
print(mean(error))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=100)
act1 = mx.symbol.Activation(fc1, name='sig1', act_type='tanh')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=10, array.batch.size=200,
learning.rate=2e-4, momentum=0.9, eval.metric=mx.metric.rmse)
library(mxnet)
data <- mx.symbol.Variable("data")
numtot <- 10
numep <- 20
train.ind = seq(1,numtot*numep,1)
train.x = numeric(200)
train.y = numeric(200)
test.x = rnorm(200, 3, 1)
test.y = rep(3,200)
es = 1
es.t = numeric(1)
mu.t = numeric(1)
for (i in 1:numtot){
mu <- runif(1, min = -1, max = 1)
for (z in 1:numep){
x <- rnorm(200, mu, 1)
train.x = append(train.x,x)
train.y = append(train.y,rep(mu,200))
es <- 1/200 * sum(x)
es.t <- append(es.t,es)
mu.t <- append(mu.t,mu)
}
}
error <- sqrt((es.t-mu.t)^2)
print(mean(error))
fc1 <- mx.symbol.FullyConnected(data, num_hidden=100)
act1 = mx.symbol.Activation(fc1, name='tanh1', act_type='tanh')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=50)
act1 = mx.symbol.Activation(fc1, name='tanh2', act_type='tanh')
fc2 <- mx.symbol.FullyConnected(act1, num_hidden=1)
# Use linear regression for the output layer
lro <- mx.symbol.LinearRegressionOutput(fc2)
mx.set.seed(0)
model <- mx.model.FeedForward.create(lro, X=train.x, y=train.y,
ctx=mx.gpu(), num.round=10, array.batch.size=200,
learning.rate=2e-4, momentum=0.9, eval.metric=mx.metric.rmse)
preds = predict(model, test.x)
print(sqrt(mean((preds-test.y)^2)))
